{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Convolutional Autoencoder***  \n",
    "MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "from keras import regularizers\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import dataset** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "\n",
    "max_value = float(X_train.max())\n",
    "X_train = X_train.astype(\"float32\")/max_value\n",
    "X_test = X_test.astype(\"float32\")/max_value\n",
    "\n",
    "X_train = X_train.reshape((len(X_train), 28, 28, 1))\n",
    "X_test = X_test.reshape((len(X_test), 28, 28, 1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential()\n",
    "\n",
    "# Encoder layers\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation = \"relu\", padding = \"same\", \n",
    "    input_shape = X_train.shape[1:]))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding = \"same\"))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation = \"relu\", padding = \"same\"))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding = \"same\"))\n",
    "autoencoder.add(Conv2D(4, (3, 3), strides = (2, 2), activation = \"relu\", padding = \"same\")) # Conv2D(8, ...)\n",
    "\n",
    "# padding = \"same\": the size of the feature map stays the same, e.g. first conv layer: 28x28\n",
    "\n",
    "# Flatten encoding for visualization\n",
    "autoencoder.add(Flatten())\n",
    "autoencoder.add(Reshape((4, 4, 4))) # (4, 4, 8)\n",
    "\n",
    "# Decoder layers\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation = \"relu\", padding = \"same\"))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation = \"relu\", padding = \"same\"))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation = \"relu\"))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(1, (3, 3), activation = \"sigmoid\", padding = \"same\"))\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the **encoder** model from the autoencoder, we’re going to use a slightly different approach than before. Rather than extracting the first 6 layers, we’re going to create a new Model with the same input as the autoencoder, but the output will be that of the flattening layer. As a side note, this is a very useful technique for grabbing submodels for things like transfer learning.  \n",
    "\n",
    "The encoded image is a vector of length 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(\n",
    "    inputs = autoencoder.input, \n",
    "    outputs = autoencoder.get_layer(\"flatten_1\").output)\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"binary_crossentropy\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    epochs = epochs,\n",
    "    batch_size = 128,\n",
    "    validation_data = (X_test, X_test),\n",
    "    callbacks = [PlotLossesKeras()])\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "print(f\"Training time: {end_time} seconds for {epochs} epochs\")\n",
    "print(f\"Training time: {end_time/epochs} per epoch on average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Models/conv_autoencoder.model\")\n",
    "encoder.save(\"Models/conv_autoencoder_encoder.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model(\"Models/conv_autoencoder.model\")\n",
    "encoder = load_model(\"Models/conv_autoencoder_encoder.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "np.random.seed(34)\n",
    "\n",
    "encoded_imgs = encoder.predict(X_test)\n",
    "decoded_imgs = autoencoder.predict(X_test)\n",
    "\n",
    "plt.figure(figsize = (18, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    j = np.random.randint(0, len(X_test))\n",
    "    # original image\n",
    "    ax = plt.subplot(3, n, i+1)\n",
    "    ax.set_title(f\"[{j}]\")\n",
    "    plt.imshow(X_test[j].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # encoded image\n",
    "    ax = plt.subplot(3, n, i+1+n)\n",
    "    plt.imshow(encoded_imgs[j].reshape(4, 16))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # reconstructed image\n",
    "    ax = plt.subplot(3, n, i+1+2*n)\n",
    "    plt.imshow(decoded_imgs[j].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "seed = lambda k: int(99/(2*k+1)*13) # arbitrary mapping from k to some seed\n",
    "\n",
    "# k rows of images\n",
    "for k in range(8):\n",
    "    np.random.seed(seed(k))\n",
    "    plt.figure(figsize = (18, 4))\n",
    "    for i in range(n):\n",
    "        j = np.random.randint(0, len(X_test))\n",
    "        ax = plt.subplot(1, n, i+1)\n",
    "        plt.imshow(encoded_imgs[j].reshape(4, 16))\n",
    "        ax.set_title(f\"[{j}]\")\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
